{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from eeSAR.s1 import s1_collection, s1_timescan\n",
    "from datetime import datetime as dt, timedelta\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our file with tscan, srtm, landcover already sampled\n",
    "gdf = gpd.read_file('/home/vollrath/Indonesia_sm/samples_all/combined_s1_extract.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAux(image):\n",
    "    \n",
    "        \n",
    "    def addGLDAS(image):\n",
    "\n",
    "        def set_resample(image):\n",
    "            \"\"\" Set resampling of the image to bilinear\"\"\"\n",
    "            return image.resample()\n",
    "        \n",
    "        def add_date_difference(image):\n",
    "\n",
    "            return image.set(\n",
    "                'dateDist',\n",
    "                ee.Number(image.get('system:time_start')).subtract(t.millis()).abs()\n",
    "            )\n",
    "\n",
    "\n",
    "        t = image.date()\n",
    "        fro = t.advance(ee.Number(-30), 'days')\n",
    "        #to = t.advance(ee.Number(10), 'days')\n",
    "\n",
    "        gldas = ee.ImageCollection(\"NASA/GLDAS/V021/NOAH/G025/T3H\") \\\n",
    "            .select('SoilMoi0_10cm_inst') \\\n",
    "            .filterBounds(image.geometry()) \\\n",
    "            .map(set_resample)\\\n",
    "            \n",
    "        #gldas_stat = gldas.reduce(\n",
    "        #        ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True)\n",
    "        #    ).rename('gldas_mean', 'gldas_stddev')\n",
    "        \n",
    "        gldas = gldas.filterDate(fro, t).map(add_date_difference)\n",
    "            \n",
    "        sm_gldas = gldas.sort('dateDist').first().rename('sm_1')\n",
    "\n",
    "        gldas_3day = gldas.filterDate(t.advance(ee.Number(-3), 'days'), t)\n",
    "        gldas_3day = gldas_3day.sum().divide(gldas_3day.count()).rename('sm_3')\n",
    "\n",
    "        gldas_7day = gldas.filterDate(t.advance(ee.Number(-7), 'days'), t)\n",
    "        gldas_7day = gldas_7day.sum().divide(gldas_7day.count()).rename('sm_7')\n",
    "\n",
    "        gldas_30day = gldas.sum().divide(gldas.count()).rename('sm_30')\n",
    "\n",
    "        # image = image.addBands(gldas_stat)\n",
    "        return image.addBands(sm_gldas).addBands(gldas_3day).addBands(gldas_7day).addBands(gldas_30day)\n",
    "    \n",
    "    \n",
    "    def addGPM(image):\n",
    "\n",
    "        def set_resample(image):\n",
    "            \"\"\" Set resampling of the image to bilinear\"\"\"\n",
    "            return image.resample()\n",
    "\n",
    "        def add_date_difference(image):\n",
    "\n",
    "            return image.set(\n",
    "                'dateDist',\n",
    "                ee.Number(image.get('system:time_start')).subtract(t.millis()).abs()\n",
    "            )\n",
    "\n",
    "        t = image.date()\n",
    "        # t = ee.Date(feature.get('date').getInfo()['value'])\n",
    "        fro = t.advance(ee.Number(-30), 'days')\n",
    "\n",
    "        gpm = ee.ImageCollection('NASA/GPM_L3/IMERG_V06') \\\n",
    "            .filterBounds(image.geometry()) \\\n",
    "            .filterDate(fro, t) \\\n",
    "            .select('HQprecipitation') \\\n",
    "            .map(add_date_difference) \\\n",
    "            .map(set_resample)\n",
    "\n",
    "\n",
    "        gpm_closest = gpm.filterDate(t.advance(ee.Number(-1), 'days'), t)  \n",
    "        gpm_closest = gpm_closest.sum().divide(gpm_closest.count()).rename('precipitation')\n",
    "\n",
    "        gpm_3day = gpm.filterDate(t.advance(ee.Number(-3), 'days'), t)\n",
    "        gpm_3day = gpm_3day.sum().divide(gpm_3day.count()).rename('prec_3')\n",
    "\n",
    "        gpm_7day = gpm.filterDate(t.advance(ee.Number(-7), 'days'), t)\n",
    "        gpm_7day = gpm_7day.sum().divide(gpm_7day.count()).rename('prec_7')\n",
    "\n",
    "        gpm_30day = gpm.sum().divide(gpm.count()).rename('prec_30')\n",
    "\n",
    "        return image.addBands(gpm_closest).addBands(gpm_3day).addBands(gpm_7day).addBands(gpm_30day)\n",
    "\n",
    "    image = addGLDAS(image)\n",
    "    image = addGPM(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Aux(i, row):\n",
    "    \n",
    "    point = ee.Geometry.Point(row.lon, row.lat)\n",
    "    \n",
    "    # get the image\n",
    "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT')\\\n",
    "        .filter(ee.Filter.eq('system:index', row['scene_id'])).first()\n",
    "\n",
    "    image = addAux(s1)\n",
    "\n",
    "    image_red = image.reduceRegion(\n",
    "        reducer=ee.Reducer.toList(),\\\n",
    "        geometry=point.buffer(150),\\\n",
    "        maxPixels=1e13,\\\n",
    "        scale=100\n",
    "    );\n",
    "\n",
    "    data_dict = image_red.getInfo()\n",
    "\n",
    "    bandlist = [\n",
    "     #'VV', 'VH', 'VVVH_ratio', 'angle', 'LIA', #'layover', 'shadow', 'no_data_mask', \n",
    "     'precipitation', 'prec_3', 'prec_7', 'prec_30', \n",
    "     #'gldas_mean', 'gldas_stddev',\n",
    "     'sm_1', 'sm_3', 'sm_7', 'sm_30',\n",
    "     #'elevation', 'aspect', 'slope', \n",
    "     #'landcover',\n",
    "     #'kVV_mean', 'kVV_stdDev', 'kVV_p5', 'kVV_p95', 'kVH_mean', 'kVH_stdDev', 'kVH_p5', 'kVH_p95', \n",
    "     #'VV_mean', 'VV_stdDev', 'VV_p5', 'VV_p95', 'VH_mean', 'VH_stdDev', 'VH_p5', 'VH_p95'\n",
    "    ]\n",
    "\n",
    "    for band in bandlist:\n",
    "        if band == 'landcover':\n",
    "            counts = np.bincount(data_dict[band])\n",
    "            row[band] = np.argmax(counts)\n",
    "        else:\n",
    "            row[band] = np.mean(data_dict[band])\n",
    "\n",
    "    d = {}\n",
    "    d[i] = row\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df.to_pickle(f'/home/vollrath/Indonesia_sm/samples_all/{i}.aux.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 1495:  51%|█████     | 1496/2928 [2:04:42<1:54:01,  4.78s/it] "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "j = 496\n",
    "with tqdm(initial=j, total=len(gdf), file=sys.stdout) as pbar:\n",
    "    for i, row in gdf.iterrows():\n",
    "        \n",
    "        if i >= j:\n",
    "        \n",
    "            ec = None\n",
    "            while ec is None != 0:\n",
    "                p1 = Process(target=get_Aux, args=(i, row, ), name='Process')\n",
    "                p1.start()\n",
    "                p1.join(timeout=180)\n",
    "                p1.terminate()\n",
    "                ec = p1.exitcode\n",
    "\n",
    "            pbar.set_description('processed: %d' % (i))\n",
    "            pbar.update(1)\n",
    "            # get_Aux(i, row)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
