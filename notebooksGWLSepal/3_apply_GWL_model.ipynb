{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from eeSAR.s1 import s1_collection, s1_timescan\n",
    "from datetime import datetime as dt, timedelta\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAux(image):\n",
    "\n",
    "    def set_resample(image):\n",
    "        \"\"\" Set resampling of the image to bilinear\"\"\"\n",
    "        return image.resample()\n",
    "    \n",
    "    def addGEDI(image):\n",
    "        \n",
    "        gedi = ee.ImageCollection('users/potapovpeter/GEDI_V27').filterBounds(image.geometry()).mosaic().rename('canopy_hei')\n",
    "        \n",
    "        return image.addBands(gedi)\n",
    "    \n",
    "    \n",
    "    def addHansen(image):\n",
    "        \n",
    "\n",
    "        coll_dict = {\n",
    "            '2012': ee.Image(\"UMD/hansen/global_forest_change_2012_v1_0\"),\n",
    "            '2013': ee.Image(\"UMD/hansen/global_forest_change_2013_v1_1\"),\n",
    "            '2014': ee.Image(\"UMD/hansen/global_forest_change_2014_v1_2\"),\n",
    "            '2015': ee.Image(\"UMD/hansen/global_forest_change_2015_v1_3\"),\n",
    "            '2016': ee.Image(\"UMD/hansen/global_forest_change_2016_v1_4\"),\n",
    "            '2017': ee.Image(\"UMD/hansen/global_forest_change_2017_v1_5\"),\n",
    "            '2018': ee.Image(\"UMD/hansen/global_forest_change_2018_v1_6\"),\n",
    "            '2019': ee.Image(\"UMD/hansen/global_forest_change_2019_v1_7\"),\n",
    "        }\n",
    "        \n",
    "        year = image.getInfo()['properties']['system:index'][17:21]\n",
    "        year = '2019' if year == '2020' else year\n",
    "        \n",
    "        hansen = coll_dict[year]\n",
    "        \n",
    "        b3 = hansen.select(['last_b30'], ['B3'])\n",
    "        b4 = hansen.select(['last_b40'], ['B4'])\n",
    "        ndvi = (b4.subtract(b3)).divide(b4.add(b3)).rename('ndvi')\n",
    "        \n",
    "        return image.addBands(ndvi)\n",
    "        \n",
    "    def addGLDAS(image):\n",
    "\n",
    "        def add_date_difference(image):\n",
    "\n",
    "            return image.set(\n",
    "                'dateDist',\n",
    "                ee.Number(image.get('system:time_start')).subtract(t.millis()).abs()\n",
    "            )\n",
    "    \n",
    "        t = image.date()\n",
    "        fro = t.advance(ee.Number(-30), 'days')\n",
    "        #to = t.advance(ee.Number(10), 'days')\n",
    "\n",
    "        gldas = ee.ImageCollection(\"NASA/GLDAS/V021/NOAH/G025/T3H\") \\\n",
    "            .select('SoilMoi0_10cm_inst') \\\n",
    "            .filterBounds(image.geometry()) \\\n",
    "            .filterDate(fro, t) \\\n",
    "            .map(set_resample) \\\n",
    "            .map(add_date_difference)\n",
    "            \n",
    "        #gldas_stat = gldas.reduce(\n",
    "        #        ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True)\n",
    "        #    ).rename('gldas_mean', 'gldas_stddev')\n",
    "        \n",
    "        #gldas = gldas.filterDate(fro, t).map(add_date_difference)\n",
    "            \n",
    "        sm_gldas = gldas.sort('dateDist').first().rename('sm_1')\n",
    "\n",
    "        gldas_3day = gldas.filterDate(t.advance(ee.Number(-3), 'days'), t)\n",
    "        gldas_3day = gldas_3day.sum().divide(gldas_3day.count()).rename('sm_3')\n",
    "\n",
    "        gldas_7day = gldas.filterDate(t.advance(ee.Number(-7), 'days'), t)\n",
    "        gldas_7day = gldas_7day.sum().divide(gldas_7day.count()).rename('sm_7')\n",
    "\n",
    "        gldas_30day = gldas.sum().divide(gldas.count()).rename('sm_30')\n",
    "\n",
    "        # image = image.addBands(gldas_stat)\n",
    "        return image.addBands(sm_gldas).addBands(gldas_3day).addBands(gldas_7day).addBands(gldas_30day)\n",
    "    \n",
    "    \n",
    "    def addGPM(image):\n",
    "\n",
    "        def add_date_difference(image):\n",
    "\n",
    "            return image.set(\n",
    "                'dateDist',\n",
    "                ee.Number(image.get('system:time_start')).subtract(t.millis()).abs()\n",
    "            )\n",
    "\n",
    "        t = image.date()\n",
    "        # t = ee.Date(feature.get('date').getInfo()['value'])\n",
    "        fro = t.advance(ee.Number(-30), 'days')\n",
    "\n",
    "        gpm = ee.ImageCollection('NASA/GPM_L3/IMERG_V06') \\\n",
    "            .filterBounds(image.geometry()) \\\n",
    "            .filterDate(fro, t) \\\n",
    "            .select('HQprecipitation') \\\n",
    "            .map(add_date_difference) \\\n",
    "            .map(set_resample)\n",
    "\n",
    "\n",
    "        gpm_closest = gpm.filterDate(t.advance(ee.Number(-1), 'days'), t)  \n",
    "        gpm_closest = gpm_closest.sum().divide(gpm_closest.count()).rename('precipitat')\n",
    "\n",
    "        gpm_3day = gpm.filterDate(t.advance(ee.Number(-3), 'days'), t)\n",
    "        gpm_3day = gpm_3day.sum().divide(gpm_3day.count()).rename('prec_3')\n",
    "\n",
    "        gpm_7day = gpm.filterDate(t.advance(ee.Number(-7), 'days'), t)\n",
    "        gpm_7day = gpm_7day.sum().divide(gpm_7day.count()).rename('prec_7')\n",
    "\n",
    "        gpm_30day = gpm.sum().divide(gpm.count()).rename('prec_30')\n",
    "\n",
    "        return image.addBands(gpm_closest).addBands(gpm_3day).addBands(gpm_7day).addBands(gpm_30day)\n",
    "\n",
    "    def addSRTM(image):\n",
    "\n",
    "        srtm = ee.Image('USGS/SRTMGL1_003').resample()\n",
    "        aspect = ee.Terrain.aspect(srtm).rename('aspect')\n",
    "        slope = ee.Terrain.slope(srtm).rename('slope')\n",
    "\n",
    "        return image.addBands(srtm.select('elevation').addBands(aspect).addBands(slope))\n",
    "       \n",
    "    def addGlobCover(image):\n",
    "        \n",
    "        lc = ee.Image(\"ESA/GLOBCOVER_L4_200901_200912_V2_3\")\n",
    "        return image.addBands(lc)\n",
    "    \n",
    "    image = addGPM(image)\n",
    "    image = addGLDAS(image)\n",
    "    image = addHansen(image)\n",
    "    image = addGEDI(image)\n",
    "    \n",
    "    #image = addSRTM(image)\n",
    "    #image = addGlobCover(image)\n",
    "                                    \n",
    "    return image\n",
    "\n",
    "\n",
    "def addTscans(image):\n",
    "    \n",
    "    def toLn(image):\n",
    "        \n",
    "        ln = image.select(['VV', 'VH']).log().rename(['VV', 'VH'])\n",
    "        return image.addBands(ln, None, True)\n",
    "    \n",
    "    def toLin(image):\n",
    "        \n",
    "        lin = ee.Image(10).pow(image.select(['VV', 'VH']).divide(10)).rename(['VV', 'VH'])\n",
    "        return image.addBands(lin, None, True)\n",
    "        \n",
    "    track_nr = image.get('relativeOrbitNumber_start').getInfo()\n",
    "    orbit = image.get('orbitProperties_pass').getInfo()\n",
    "    \n",
    "    tSeries = s1_collection.create(\n",
    "        region=image.geometry(),\n",
    "        orbits=[orbit],\n",
    "        start_date='2014-01-01',\n",
    "        end_date='2021-01-01',\n",
    "        add_ratio=False,\n",
    "        add_ND_ratio=False,\n",
    "        speckle_filter='NONE',\n",
    "        radiometric_correction='TERRAIN',\n",
    "        slope_correction_dict={'model': 'surface', 'dem': 'USGS/SRTMGL1_003', 'buffer': 50},\n",
    "        db=False,\n",
    "        outlier_removal='AGGRESSIVE'\n",
    "        ) \\\n",
    "        .filterMetadata('relativeOrbitNumber_start', 'equals', track_nr)\n",
    "    \n",
    "    # create combined reducer\n",
    "    reducer = ee.Reducer.mean() \\\n",
    "        .combine(ee.Reducer.stdDev(), '', True) \\\n",
    "        .combine(ee.Reducer.percentile([5, 95]), '', True)\n",
    "    \n",
    "    # create log timescan (k variables)\n",
    "    tScanLn = tSeries.map(toLn).select(['VV', 'VH']).reduce(reducer).select(\n",
    "    ['VV_mean', 'VV_stdDev', 'VV_p5', 'VV_p95', 'VH_mean', 'VH_stdDev', 'VH_p5', 'VH_p95'],\n",
    "    ['kVV_mean', 'kVV_stdDev', 'kVV_p5', 'kVV_p95', 'kVH_mean', 'kVH_stdDev', 'kVH_p5', 'kVH_p95'])\n",
    "    \n",
    "    # create linear timescan\n",
    "    tScanLin = tSeries.map(toLin).select(['VV', 'VH']).reduce(reducer)\n",
    "    \n",
    "    return image.addBands(tScanLn).addBands(tScanLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(image):\n",
    "    \n",
    "    mask_classification = ee.Image('users/andreasvollrath/GWL_indonesia/classified_asset')\n",
    "    \n",
    "    \n",
    "    # single image mask\n",
    "    vv = image.select('VV')\n",
    "    vh = image.select('VH')\n",
    "    lia = image.select('LIA')\n",
    "\n",
    "    maskvv = vv.gte(-30).bitwiseAnd(vv.lt(0))\n",
    "    maskvh = vh.gte(-30).bitwiseAnd(vh.lt(0))\n",
    "    masklia = lia.gte(20).bitwiseAnd(vh.lt(45))\n",
    "    \n",
    "    mask_image = maskvv \\\n",
    "        .bitwiseAnd(maskvh) \\\n",
    "        .bitwiseAnd(masklia) \n",
    "    \n",
    "    # mask based on SD (to exclude less variable pixels)\n",
    "    kvvSd = image.select('kVV_stdDev').gt(0.1)\n",
    "    kvhSd = image.select('kVH_stdDev').gt(0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Globcover mask\n",
    "    glbcvr = image.select('landcover')\n",
    "    valLClist = [11, 14, 20, 30, 120, 140, 150]\n",
    "    lcmask = glbcvr.eq(valLClist[0]) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[1])) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[2])) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[3])) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[4])) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[5])) \\\n",
    "        .bitwiseOr(glbcvr.eq(valLClist[6]))\n",
    "\n",
    "    \n",
    "    return image \\\n",
    "        .updateMask(mask_image \\\n",
    "            .bitwiseAnd(kvvSd) \\\n",
    "            .bitwiseAnd(kvhSd) \\\n",
    "            .bitwiseAnd(mask_classification.neq(2))\n",
    "            #.bitwiseAnd(mask_class) \n",
    "            #.bitwiseAnd(lcmask)\n",
    "        )\n",
    "\n",
    "def classify(i, image):\n",
    "    \n",
    "    geom = image.geometry().bounds(10)\n",
    "    \n",
    "    # add aux data\n",
    "    image = addAux(image)\n",
    "    image = addTscans(image)\n",
    "        \n",
    "    # apply mask\n",
    "    image = mask(image)\n",
    "    \n",
    "    # get properties and construct out filename\n",
    "    props = image.getInfo()['properties']\n",
    "    scene_id = props['system:index']\n",
    "    acq_date = scene_id[17:25]\n",
    "    \n",
    "    orbit = props['orbitProperties_pass']\n",
    "    orbitDir = 'A' if orbit == 'ASCENDING' else 'D'\n",
    "    track_nr = image.get('relativeOrbitNumber_start').getInfo()\n",
    "    \n",
    "    fileName = f'{orbitDir}{track_nr}_{acq_date}.{scene_id}.GWL'\n",
    "    \n",
    "    # get data for train model\n",
    "    table = ee.FeatureCollection('users/andreasvollrath/GWL_indonesia/final_training_data_extra2')\n",
    "    label = 'GWL_rata'\n",
    "    bandlist = [\n",
    "     'VV', 'VH', 'VVVH_ratio', 'angle', 'LIA', #'layover', 'shadow', 'no_data_mask', \n",
    "     'precipitat', 'prec_3', 'prec_7', 'prec_30', \n",
    "     'sm_1', 'sm_3', 'sm_7', 'sm_30', \n",
    "     #'canopy_hei',\n",
    "     #'ndvi',\n",
    "     #'elevation', 'aspect', 'slope', 'landcover',\n",
    "     'kVV_mean', 'kVV_stdDev', 'kVV_p5', 'kVV_p95', 'kVH_mean', 'kVH_stdDev', 'kVH_p5', 'kVH_p95', \n",
    "     'VV_mean', 'VV_stdDev', 'VV_p5', 'VV_p95', 'VH_mean', 'VH_stdDev', 'VH_p5', 'VH_p95'\n",
    "    ]\n",
    "    \n",
    "    # train classifier\n",
    "    trained = ee.Classifier.smileRandomForest(250).setOutputMode('REGRESSION').train(table, label, bandlist)\n",
    "    \n",
    "    # classify\n",
    "    classified = image.select(bandlist).classify(trained).clip(geom)\n",
    "    \n",
    "    # create export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "                    image=classified,\n",
    "                    description=f'{fileName}',\n",
    "                    folder='gwl_model_ts_nolc_noSRTM_masked',\n",
    "                    fileNamePrefix=f'{fileName}',\n",
    "                    region=geom.coordinates().getInfo(),\n",
    "                    scale=100,\n",
    "                    maxPixels=1e12\n",
    "                )\n",
    "\n",
    "    # launch export task\n",
    "    task.start()\n",
    "    print(task.status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'READY', 'description': 'D105_20180325.S1A_IW_GRDH_1SDV_20180325T215940_20180325T220005_021177_024684_4E51.GWL', 'creation_timestamp_ms': 1605001730579, 'update_timestamp_ms': 1605001730579, 'start_timestamp_ms': 0, 'task_type': 'EXPORT_IMAGE', 'id': 'XTZXWI2DPDUYQZEHDGELUNFO', 'name': 'projects/earthengine-legacy/operations/XTZXWI2DPDUYQZEHDGELUNFO'}\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "start = '2015-01-01'\n",
    "end = '2017-12-31'\n",
    "\n",
    "# SouthKalimantan\n",
    "geom = ee.Geometry.Polygon(\n",
    "    [[[113.25,-3.5],[114.5,-3.5], [114.5,-1.8],[113.25,-1.8],[113.25,-3.5]]]\n",
    ")\n",
    "\n",
    "phu_geom = ee.FeatureCollection('users/marortpab/FAO/indonesia/cs4/selected_phu').geometry()\n",
    "\n",
    "\n",
    "\n",
    "images = s1_collection.create(\n",
    "    region=geom, \n",
    "    start_date=start,\n",
    "    end_date=end, \n",
    "    add_ND_ratio=False,\n",
    "    speckle_filter='QUEGAN',\n",
    "    radiometric_correction='TERRAIN',\n",
    "    slope_correction_dict={'model': 'surface', 'dem': 'USGS/SRTMGL1_003', 'buffer': 50}, #'CGIAR/SRTM90_V4'\n",
    "    db=True\n",
    ")\n",
    "\n",
    "images_list = images.toList(images.size())\n",
    "images_size = images_list.size().getInfo()\n",
    "\n",
    "for i in range(images_size):\n",
    "\n",
    "        if i == 0:\n",
    "            continue \n",
    "            \n",
    "        image = ee.Image(images_list.get(i))\n",
    "        image_valid = image.select('VV').neq(0)\n",
    "        \n",
    "        # check on overlap\n",
    "        image_geom = image_valid.reduceToVectors(\n",
    "              geometry=geom,\n",
    "              scale=500, \n",
    "              maxPixels=1e12\n",
    "        )\n",
    "\n",
    "        intersect = phu_geom.intersection(image_geom, 10)\n",
    "        inter_ratio = intersect.area(10).getInfo() / phu_geom.area(10).getInfo()\n",
    "        \n",
    "        if inter_ratio > 0.01:\n",
    "            ec = None\n",
    "            while ec is None != 0:\n",
    "                p1 = Process(target=classify, args=(i, image, ), name='Process')\n",
    "                p1.start()\n",
    "                p1.join(timeout=500)\n",
    "                p1.terminate()\n",
    "                ec = p1.exitcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
